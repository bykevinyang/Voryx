{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local GloVe Setup Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place local path of GloVe here\r\n",
    "GloVe_path = 'data\\glove.6B.50d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 0.418 \n"
     ]
    }
   ],
   "source": [
    "with open(GloVe_path) as f:\r\n",
    "    print(f.readline(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Drive Setup Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place path of GloVe here\r\n",
    "GloVe_path = '/gdrive/My Drive/Projects/Bumblebee/using-pretrained-glove-vectors-example/glove.6B.50d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9CCDQS2UCmeY",
    "outputId": "d3a36502-201e-482a-f566-20636ced8ac7"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e5b0420cd036>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/gdrive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FQCoqXlbCoge",
    "outputId": "4117aa74-2863-4056-f19d-074db542a096"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 0.418 \n"
     ]
    }
   ],
   "source": [
    "with open('/gdrive/My Drive/Projects/Bumblebee/using-pretrained-glove-vectors-example/glove.6B.50d.txt', 'r') as f:\n",
    "  print(f.readline(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XrBm4NW9Cp9d"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# # from numpy import arccos\n",
    "# from scipy import spatial\n",
    "# # import matplotlib.pyplot as plt\n",
    "# # from sklearn.manifold import TSNE\n",
    "# # from sklearn.metrics.pairwise import cosine_similarity\n",
    "# # from collections import OrderedDict\n",
    "# import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "RjqfEL5IzfGD"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "i9fB_N634jUY"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kevin Yang\\anaconda3\\envs\\Voryx\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\Kevin Yang\\anaconda3\\envs\\Voryx\\lib\\site-packages\\nltk\\draw\\table.py\", line 198, in _resize_column_motion_cb\n",
      "    lb[\"width\"] = max(3, lb[\"width\"] + (x1 - x2) // charwidth)\n",
      "  File \"C:\\Users\\Kevin Yang\\anaconda3\\envs\\Voryx\\lib\\tkinter\\__init__.py\", line 1657, in __setitem__\n",
      "    self.configure({key: value})\n",
      "  File \"C:\\Users\\Kevin Yang\\anaconda3\\envs\\Voryx\\lib\\tkinter\\__init__.py\", line 1646, in configure\n",
      "    return self._configure('configure', cnf, kw)\n",
      "  File \"C:\\Users\\Kevin Yang\\anaconda3\\envs\\Voryx\\lib\\tkinter\\__init__.py\", line 1636, in _configure\n",
      "    self.tk.call(_flatten((self._w, cmd)) + self._options(cnf))\n",
      "_tkinter.TclError: expected integer but got \"19.0\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load GloVe into dictionary for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "KNeOyFzjCquE"
   },
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "with open(GloVe_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        token = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[token] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "8pLgLiAZp6Iv"
   },
   "outputs": [],
   "source": [
    "phrases = {\n",
    "          \"hi there\" : \"video1\",  \n",
    "          \"how you doing\" : \"video2\",\n",
    "          \"who are you\" : \"video3\",\n",
    "          \"i am you\" : \"video3\",\n",
    "          \"my name is josh\" : \"video3\",\n",
    "          \"i am kevin\" : \"video3\",\n",
    "          \"i am josh\" : \"vid4\",\n",
    "          \"i josh am\" : \"vid5\",\n",
    "          \"who is kevin\" : \"joe\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kunHlNHLp8ow"
   },
   "source": [
    "Class Vorx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "tf01PNQ6p-Cg"
   },
   "outputs": [],
   "source": [
    "class Vorx:\r\n",
    "\r\n",
    "  def __init__(self, phrase_pool, phrase, embeddings_dict, size=15):\r\n",
    "    self.phrase_pool = phrase_pool\r\n",
    "    self.embeddings_dict = embeddings_dict\r\n",
    "    self.phrase = phrase\r\n",
    "    self.size = size\r\n",
    "    self.embedded_phrase_pool = self.vector_sort(self.embed_phrases()[0])\r\n",
    "    self.embedded_phrase_mapping = self.embed_phrases()[1]\r\n",
    "\r\n",
    "  def __repr__(self):\r\n",
    "    counter = 0\r\n",
    "\r\n",
    "    output = \"\"\r\n",
    "    output += \"Sorted Embedded Phrase Pool:\"\r\n",
    "    output += \"\\n\"\r\n",
    "\r\n",
    "    for line in self.embedded_phrase_pool:\r\n",
    "      phrase = self.embedded_phrase_mapping[line]\r\n",
    "\r\n",
    "      output += str(counter) + \".\"\r\n",
    "      output += \"\\t\"\r\n",
    "      output += phrase\r\n",
    "      output += \"\\t -> \\t\"\r\n",
    "      output += str(line)\r\n",
    "      output += \"\\n\"\r\n",
    "    \r\n",
    "      counter += 1\r\n",
    "    return output\r\n",
    "\r\n",
    "  def embed_sentence(self, sentence):\r\n",
    "    # O(n)\r\n",
    "    # Embed the sentence by getting the embed for each word\r\n",
    "    words = sentence.split()\r\n",
    "    embed = []\r\n",
    "    for word in words:\r\n",
    "      embed.append(self.embeddings_dict[word][1])\r\n",
    "    return embed\r\n",
    "\r\n",
    "  def length_normalize(self, words, size=15):\r\n",
    "    # O(n)\r\n",
    "    # Make the length of each vector the same to size by adding zeros\r\n",
    "    length = len(words)\r\n",
    "    output = words.copy()\r\n",
    "\r\n",
    "    if length < self.size:\r\n",
    "      difference = self.size - length\r\n",
    "      for i in range(difference):\r\n",
    "        output.append(0)\r\n",
    "      return tuple(output)\r\n",
    "    elif length > self.size:\r\n",
    "        raise Exception(\"Input length is greater than size. Size is: \" + str(self.size))\r\n",
    "    else:\r\n",
    "      return tuple(output)\r\n",
    "\r\n",
    "  def embed_phrases(self):\r\n",
    "    # Embed the phrases in phrase pool, internal\r\n",
    "    embedded_phrases = []                     # List storing embeds\r\n",
    "    mapping = {}                              # Dict used to map embed to phrase\r\n",
    "\r\n",
    "    for phrase in self.phrase_pool:\r\n",
    "      embed = self.embed_sentence(phrase)          # Getting embeding of sentence\r\n",
    "      embed = self.length_normalize(embed, self.size)   # Make embed vector length same\r\n",
    "    \r\n",
    "      embedded_phrases.append(embed)\r\n",
    "      mapping[embed] = phrase\r\n",
    "\r\n",
    "    return embedded_phrases, mapping\r\n",
    "  \r\n",
    "  def vector_sort(self, vectors):\r\n",
    "    # Sort the vectors in order from least to greatest\r\n",
    "    return sorted(vectors, key=lambda x: x[0], reverse=False)\r\n",
    "  \r\n",
    "  def cosine_similarity(self, embed1, embed2):\r\n",
    "    # O(1)\r\n",
    "    # Gets angle between two vectors -> represents similarity\r\n",
    "    if len(embed1) != len(embed2):\r\n",
    "      raise Exception(\"Inputs are not same length. Embed1 is \" + str(len(embed1)) + \" while Embed2 is \" + str(len(embed2)))\r\n",
    "    return spatial.distance.cosine(embed1, embed2)\r\n",
    "\r\n",
    "\r\n",
    "  def find_phrase(self, phrase):\r\n",
    "    # Finds most similar phrase from pool to the inputted phrase\r\n",
    "    # Outputs a tuple (In pool, index)\r\n",
    "    sentence_in_question = self.embed_sentence(phrase)\r\n",
    "    sentence_in_question = self.length_normalize(sentence_in_question, self.size)\r\n",
    "\r\n",
    "    low = 0\r\n",
    "    high = len(self.embedded_phrase_pool) - 1\r\n",
    "\r\n",
    "    first_time = True\r\n",
    "\r\n",
    "    while low <= high:\r\n",
    "      mid = (high + low) // 2\r\n",
    "\r\n",
    "      mid_embedding = self.embedded_phrase_pool[mid]\r\n",
    "\r\n",
    "      if mid_embedding == sentence_in_question:\r\n",
    "        first_time = False\r\n",
    "        return True, mid\r\n",
    "      # If x is greater, ignore left half\r\n",
    "      elif mid_embedding < sentence_in_question:\r\n",
    "        first_time = False\r\n",
    "        low = mid + 1\r\n",
    "\r\n",
    "      # If x is smaller, ignore right half\r\n",
    "      else:\r\n",
    "        first_time = False\r\n",
    "        high = mid - 1\r\n",
    "\r\n",
    "    if first_time:\r\n",
    "      return False, -1\r\n",
    "    else:\r\n",
    "      return False, mid\r\n",
    "\r\n",
    "  def prep_paragraph(self, paragraph):  \r\n",
    "    proper_nouns = ProperNounExtractor(paragraph)                     # Using NLTK's proper noun tagger\r\n",
    "    print(\"nouns:\", proper_nouns)\r\n",
    "\r\n",
    "    # all_words = re.split(', |\\. |; |: | ', paragraph)               # Split inputted paragraph into stand-alone words\r\n",
    "    # capitaled_words = [x for x in all_words if x[0].isupper()]      # Find words that start with capital letters\r\n",
    "\r\n",
    "    prepared_para = re.split(', |\\. |; |: ', paragraph)             # Split up paragraph by punctuation \r\n",
    "\r\n",
    "    for proper_noun in proper_nouns:\r\n",
    "      for text in prepared_para:\r\n",
    "        if proper_noun in text:\r\n",
    "          parts = text.split(\" \" + proper_noun)\r\n",
    "          for i, t in enumerate(parts):\r\n",
    "            if t == \"\":\r\n",
    "              parts[i] = proper_noun\r\n",
    "          print(parts)\r\n",
    "    return prepared_para, proper_nouns\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrTcSWfl6Tqd"
   },
   "source": [
    "stopwords\n",
    "\n",
    "averaged_perceptron_tagger\n",
    "\n",
    "punktron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "D3",
   "provenance": []
  },
  "interpreter": {
   "hash": "085fe8ee4cd864f6a655bcdbadb4bff65bd482c8187acb71c1d145b32f3f5ff9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('Voryx': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}